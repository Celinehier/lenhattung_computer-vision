{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải ảnh đầu vào\n",
    "img = cv2.imread('./face.png')\n",
    "\n",
    "# Hiển thị ảnh gốc\n",
    "cv2.imshow('Ảnh Gốc', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Bước 2: Tải mô hình đã được huấn luyện trước\n",
    "net = cv2.dnn.readNetFromCaffe('./models/deploy.prototxt.txt',\n",
    "                               './models/res10_300x300_ssd_iter_140000_fp16.caffemodel')\n",
    "                               \n",
    "# Bước 3: Chuẩn bị dữ liệu đầu vào cho mạng neuron\n",
    "# img: Đây là ảnh đầu vào mà bạn muốn nhận dạng khuôn mặt. Trong trường hợp của bạn, bạn đã đọc ảnh từ tệp \"face.png\".\n",
    "# 1.0: Đây là tỷ lệ co giãn cho ảnh. Trong trường hợp này, ảnh sẽ không bị co giãn hoặc mở rộng, và giữ nguyên kích thước ban đầu.\n",
    "# (300, 300): Đây là kích thước mà mô hình yêu cầu cho ảnh đầu vào. Mô hình mà bạn đang sử dụng mong muốn ảnh có kích thước 300x300 pixel. Do đó, bạn co giãn hoặc cắt ảnh đầu vào thành kích thước này.\n",
    "# (104, 177, 123): Đây là giá trị trung bình màu sắc được trừ đi từ mỗi pixel của ảnh. Điều này thường được sử dụng để chuẩn hóa dữ liệu đầu vào. Trong trường hợp này, các giá trị này thường được lấy từ dữ liệu huấn luyện của mô hình.\n",
    "# swapRB=False: Đây là một cờ để xác định xem có cần hoán đổi các kênh màu đỏ và xanh (Red-Blue) trong ảnh hay không. Trong trường hợp này, bạn đã đặt nó thành False, tức là không hoán đổi kênh mà\n",
    "blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), (104, 177, 123), swapRB=False)\n",
    "\n",
    "# Bước 4: Đặt dữ liệu đầu vào cho mạng\n",
    "net.setInput(blob)\n",
    "\n",
    "# Bước 5: Chạy mạng để phát hiện khuôn mặt\n",
    "detections = net.forward()\n",
    "\n",
    "print(detections.shape)     \n",
    "# Chiều đầu tiên (đầu tiên từ trái sang phải) có kích thước là 1, đại diện cho số lô (batch size) của các ảnh đầu vào. Trong trường hợp này, bạn đang xử lý một ảnh nên batch size là 1.\n",
    "# Chiều thứ hai cũng có kích thước là 1, đại diện cho số lớp (classes) hoặc số kích thước (size dimensions) trong dữ liệu đầu ra. Trong trường hợp này, bạn đang thực hiện nhận dạng khuôn mặt nên số lớp là 1.\n",
    "# Chiều thứ ba có kích thước là 200, đại diện cho số khuôn mặt được phát hiện trong một ảnh. Điều này có nghĩa rằng mô hình có khả năng phát hiện tối đa 200 khuôn mặt trong ảnh đầu vào.\n",
    "# Chiều cuối cùng có kích thước là 7, đại diện cho thông tin về mỗi khuôn mặt phát hiện. Chiều này chứa thông tin về vị trí của khuôn mặt và độ tin cậy (confidence) của việc phát hiện.\n",
    "                               \n",
    "# Bước 6: Lấy kích thước của ảnh đầu vào\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Bước 7: Duyệt qua các khuôn mặt đã được phát hiện\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # Kiểm tra nếu khuôn mặt đã phát hiện có độ tin cậy lớn hơn hoặc bằng 0.5\n",
    "    if confidence >= 0.5:\n",
    "        # Trích xuất tọa độ hình chữ nhật chuẩn hóa\n",
    "        box = detections[0, 0, i, 3:7]\n",
    "        box = box * np.array([w, h, w, h])\n",
    "        box = box.astype(int)\n",
    "        startx, starty, endx, endy = box\n",
    "\n",
    "        # Vẽ hình chữ nhật xung quanh khuôn mặt phát hiện\n",
    "        cv2.rectangle(img, (startx, starty), (endx, endy), (0, 255, 0), 2)\n",
    "\n",
    "        # Hiển thị điểm tin cậy trên hình chữ nhật\n",
    "        text = 'Face: {:.2f}%'.format(confidence * 100)\n",
    "        cv2.putText(img, text, (startx, starty - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 2)\n",
    "\n",
    "# Hiển thị ảnh kết quả với khuôn mặt đã được phát hiện\n",
    "cv2.imshow('Kết Quả Nhận Dạng Khuôn Mặt', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h,w = img.shape[:2]\n",
    "for i in range(0,detections.shape[2]):\n",
    "    confidence = detections[0,0,i,2]\n",
    "    if confidence >= 0.5:\n",
    "        #print(confidence)\n",
    "        # bounding box (3:7)\n",
    "        box = detections[0,0,i,3:7] # normalized bounding box values\n",
    "        box = box*np.array([w,h,w,h])\n",
    "        box = box.astype(int)\n",
    "        startx, starty , endx, endy = box\n",
    "        # draw the rectangle face\n",
    "        cv2.rectangle(img,(startx,starty),(endx,endy),(0,255,0))\n",
    "        \n",
    "        \n",
    "        # put text\n",
    "        text = 'Face: {:.2f} %'.format(confidence*100)\n",
    "        cv2.putText(img,text,(startx,starty-10),cv2.FONT_HERSHEY_PLAIN,1,(255,255,255),)\n",
    "        \n",
    "cv2.imshow('face detect',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
